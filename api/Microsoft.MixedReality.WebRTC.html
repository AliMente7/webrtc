<!DOCTYPE html>
<!--[if IE]><![endif]-->
<html>
  
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Namespace Microsoft.MixedReality.WebRTC
   | MixedReality-WebRTC Documentation </title>
    <meta name="viewport" content="width=device-width">
    <meta name="title" content="Namespace Microsoft.MixedReality.WebRTC
   | MixedReality-WebRTC Documentation ">
    <meta name="generator" content="docfx 2.56.7.0">
    
    <link rel="shortcut icon" href="../mr-webrtc_icon.png">
    <link rel="stylesheet" href="../styles/docfx.vendor.css">
    <link rel="stylesheet" href="../styles/docfx.css">
    <link rel="stylesheet" href="../styles/main.css">
    <meta property="docfx:navrel" content="../toc.html">
    <meta property="docfx:tocrel" content="toc.html">
    
    <meta property="docfx:rel" content="../">
    
  </head>
  <body data-spy="scroll" data-target="#affix" data-offset="120" data-uid="Microsoft.MixedReality.WebRTC">
    <div id="wrapper">
      <header>
        
        <nav id="autocollapse" class="navbar navbar-inverse ng-scope" role="navigation">
          <div class="container">
            <div class="navbar-header">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
              
              <a class="navbar-brand" href="../index.html">
                <img id="logo" class="svg" src="../mr-webrtc_icon.png" alt="MixedReality-WebRTC">
                <span>MixedReality-WebRTC</span>
              </a>
            </div>
            <div class="collapse navbar-collapse" id="navbar">
              <form class="navbar-form navbar-right" id="branch-selector">
                <select name="branch"></select>
              </form>
              <form class="navbar-form navbar-right" role="search" id="search">
                <div class="form-group">
                  <input type="text" class="form-control" id="search-query" placeholder="Search" autocomplete="off">
                </div>
              </form>
            </div>
          </div>
        </nav>
        
        <div class="subnav navbar navbar-default">
          <div class="container hide-when-search" id="breadcrumb">
            <ul class="breadcrumb">
              <li></li>
            </ul>
          </div>
        </div>
      </header>
      <div class="container body-content">
        
        <div id="search-results">
          <div class="search-list">Search Results for <span></span></div>
          <div class="sr-items">
            <p><i class="glyphicon glyphicon-refresh index-loading"></i></p>
          </div>
          <ul id="pagination" data-first="First" data-prev="Previous" data-next="Next" data-last="Last"></ul>
        </div>
      </div>
      <div role="main" class="container body-content hide-when-search">
        
        <div class="sidenav hide-when-search">
          <a class="btn toc-toggle collapse" data-toggle="collapse" href="#sidetoggle" aria-expanded="false" aria-controls="sidetoggle">Show / Hide Table of Contents</a>
          <div class="sidetoggle collapse" id="sidetoggle">
            <div id="sidetoc"></div>
          </div>
        </div>
        <div class="article row grid-right">
          <div class="col-md-10">
            <article class="content wrap" id="_content" data-uid="Microsoft.MixedReality.WebRTC">
  
  <h1 id="Microsoft_MixedReality_WebRTC" data-uid="Microsoft.MixedReality.WebRTC" class="text-break">Namespace Microsoft.MixedReality.WebRTC
  </h1>
  <div class="markdown level0 summary"></div>
  <div class="markdown level0 conceptual"></div>
  <div class="markdown level0 remarks"></div>
    <h3 id="classes">Classes
  </h3>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.Argb32VideoFrameStorage.html">Argb32VideoFrameStorage</a></h4>
      <section><p>Storage for a video frame encoded in ARGB format.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.AudioTrackReadBuffer.html">AudioTrackReadBuffer</a></h4>
      <section><p>High level interface for consuming WebRTC audio tracks.
Enqueues audio frames for a <a class="xref" href="Microsoft.MixedReality.WebRTC.RemoteAudioTrack.html">RemoteAudioTrack</a> in an internal buffer as they
arrive. Users should call
<a class="xref" href="Microsoft.MixedReality.WebRTC.AudioTrackReadBuffer.html#Microsoft_MixedReality_WebRTC_AudioTrackReadBuffer_Read_System_Int32_System_Int32_System_Single___System_Int32__System_Boolean__Microsoft_MixedReality_WebRTC_AudioTrackReadBuffer_PadBehavior_">Read(Int32, Int32, Single[], out Int32, out Boolean, AudioTrackReadBuffer.PadBehavior)</a>
to read samples from the buffer when needed.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.AudioTrackSource.html">AudioTrackSource</a></h4>
      <section><p>Audio source for WebRTC audio tracks.</p>
<p>The audio source is not bound to any peer connection, and can therefore be shared by multiple audio
tracks from different peer connections. This is especially useful to share local audio capture devices
(microphones) amongst multiple peer connections when building a multi-peer experience with a mesh topology
(one connection per pair of peers).</p>
<p>The user owns the audio track source, and is in charge of keeping it alive until after all tracks using it
are destroyed, and then dispose of it. The behavior of disposing of the track source while a track is still
using it is undefined. The <a class="xref" href="Microsoft.MixedReality.WebRTC.AudioTrackSource.html#Microsoft_MixedReality_WebRTC_AudioTrackSource_Tracks">Tracks</a> property contains the list of tracks currently using the
source.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.BufferTooSmallException.html">BufferTooSmallException</a></h4>
      <section><p>Exception raised when a buffer is too small to perform the current operation.</p>
<p>Generally the buffer was provided by the caller, and this indicates that the caller
must provide a larger buffer.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.DataChannel.html">DataChannel</a></h4>
      <section><p>Encapsulates a data channel of a peer connection.</p>
<p>A data channel is a &quot;pipe&quot; allowing to send and receive arbitrary data to the
remote peer. Data channels are based on DTLS-SRTP, and are therefore secure (encrypted).
Exact security guarantees are provided by the underlying WebRTC core implementation
and the WebRTC standard itself.</p>
<p><a href="https://tools.ietf.org/wg/rtcweb/">https://tools.ietf.org/wg/rtcweb/</a>
<a href="https://www.w3.org/TR/webrtc/">https://www.w3.org/TR/webrtc/</a></p>
<p>An instance of <a class="xref" href="Microsoft.MixedReality.WebRTC.DataChannel.html">DataChannel</a> is created either by manually calling
<see cref="!:PeerConnection.AddDataChannelAsync(string,bool,bool,System.Threading.CancellationToken)"></see>
or one of its variants, or automatically by the implementation when a new data channel
is created in-band by the remote peer (<a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.html#Microsoft_MixedReality_WebRTC_PeerConnection_DataChannelAdded">DataChannelAdded</a>).
<a class="xref" href="Microsoft.MixedReality.WebRTC.DataChannel.html">DataChannel</a> cannot be instantiated directly.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.DataChannelNotOpenException.html">DataChannelNotOpenException</a></h4>
      <section><p>Exception thrown when trying to use a data channel that is not open.</p>
<p>The user should listen to the <a class="xref" href="Microsoft.MixedReality.WebRTC.DataChannel.html#Microsoft_MixedReality_WebRTC_DataChannel_StateChanged">StateChanged</a> event until the
<a class="xref" href="Microsoft.MixedReality.WebRTC.DataChannel.html#Microsoft_MixedReality_WebRTC_DataChannel_State">State</a> property is <a class="xref" href="Microsoft.MixedReality.WebRTC.DataChannel.ChannelState.html#Microsoft_MixedReality_WebRTC_DataChannel_ChannelState_Open">Open</a>
before trying to send some message with <a class="xref" href="Microsoft.MixedReality.WebRTC.DataChannel.html#Microsoft_MixedReality_WebRTC_DataChannel_SendMessage_System_Byte___">SendMessage(Byte[])</a>.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.DeviceAudioTrackSource.html">DeviceAudioTrackSource</a></h4>
      <section><p>Implementation of an audio track source producing frames captured from an audio capture device (microphone).</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.DeviceVideoTrackSource.html">DeviceVideoTrackSource</a></h4>
      <section><p>Implementation of a video track source producing frames captured from a video capture device (webcam).</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.ExternalVideoTrackSource.html">ExternalVideoTrackSource</a></h4>
      <section><p>Video source for WebRTC video tracks based on a custom source
of video frames managed by the user and external to the WebRTC
implementation.</p>
<p>This class is used to inject into the WebRTC engine a video track
whose frames are produced by a user-managed source the WebRTC engine
knows nothing about, like programmatically generated frames, including
frames not strictly of video origin like a 3D rendered scene, or frames
coming from a specific capture device not supported natively by WebRTC.
This class serves as an adapter for such video frame sources.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.I420AVideoFrameStorage.html">I420AVideoFrameStorage</a></h4>
      <section><p>Storage for a video frame encoded in I420+Alpha format.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.IceCandidate.html">IceCandidate</a></h4>
      <section><p>ICE candidate to send to a remote peer or received from it.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.IceServer.html">IceServer</a></h4>
      <section><p>ICE server configuration (STUN and/or TURN).</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.InvalidInteropNativeHandleException.html">InvalidInteropNativeHandleException</a></h4>
      <section><p>Exception thrown when an API function expects an interop handle to a valid native object,
but receives an invalid handle instead.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.Library.html">Library</a></h4>
      <section><p>Container for library-wise global settings of MixedReality-WebRTC.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.LocalAudioDeviceInitConfig.html">LocalAudioDeviceInitConfig</a></h4>
      <section><p>Configuration to initialize capture on a local audio device (microphone).</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.LocalAudioTrack.html">LocalAudioTrack</a></h4>
      <section><p>Audio track sending to the remote peer audio frames originating from
a local track source (local microphone or other audio recording device).</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.LocalAudioTrackInitConfig.html">LocalAudioTrackInitConfig</a></h4>
      <section><p>Settings for adding a local audio track backed by a local audio capture device (e.g. microphone).</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.LocalMediaTrack.html">LocalMediaTrack</a></h4>
      <section><p>Base class for media tracks sending to the remote peer.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.LocalVideoDeviceInitConfig.html">LocalVideoDeviceInitConfig</a></h4>
      <section><p>Configuration to initialize capture on a local video device (webcam).</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.LocalVideoTrack.html">LocalVideoTrack</a></h4>
      <section><p>Video track sending to the remote peer video frames originating from
a local track source.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.LocalVideoTrackInitConfig.html">LocalVideoTrackInitConfig</a></h4>
      <section><p>Settings for creating a new local video track.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.Logging.html">Logging</a></h4>
      <section><p>Logging utilities.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.MediaTrack.html">MediaTrack</a></h4>
      <section><p>Base class for media tracks sending to or receiving from the remote peer.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.MovingAverage.html">MovingAverage</a></h4>
      <section><p>Utility to manage a moving average of a time series.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.html">PeerConnection</a></h4>
      <section><p>The WebRTC peer connection object is the entry point to using WebRTC.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.StatsReport.html">PeerConnection.StatsReport</a></h4>
      <section><p>Snapshot of the statistics relative to a peer connection/track.
The various stats objects can be read through <a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.StatsReport.html#Microsoft_MixedReality_WebRTC_PeerConnection_StatsReport_GetStats__1">GetStats&lt;T&gt;()</a>.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnectionConfiguration.html">PeerConnectionConfiguration</a></h4>
      <section><p>Configuration to initialize a <a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.html">PeerConnection</a>.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.RemoteAudioTrack.html">RemoteAudioTrack</a></h4>
      <section><p>Audio track receiving audio frames from the remote peer.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.RemoteVideoTrack.html">RemoteVideoTrack</a></h4>
      <section><p>Video track receiving video frames from the remote peer.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.SctpNotNegotiatedException.html">SctpNotNegotiatedException</a></h4>
      <section><p>Exception thrown when trying to add a data channel to a peer connection after
a connection to a remote peer was established without an SCTP handshake.
When using data channels, at least one data channel must be added to the peer
connection before calling <a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.html#Microsoft_MixedReality_WebRTC_PeerConnection_CreateOffer">CreateOffer()</a> to signal
to the implementation the intent to use data channels and the need to perform a
SCTP handshake during the connection.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.SdpMessage.html">SdpMessage</a></h4>
      <section><p>SDP message passed between the local and remote peers via the user's signaling solution.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.TaskExtensions.html">TaskExtensions</a></h4>
      <section><p>Collection of extension methods for <a class="xref" href="https://docs.microsoft.com/dotnet/api/system.threading.tasks.task">Task</a>.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.Transceiver.html">Transceiver</a></h4>
      <section><p>Transceiver of a peer connection.</p>
<p>A transceiver is a media &quot;pipe&quot; connecting the local and remote peers, and used to transmit media
data (audio or video) between the peers. The transceiver has a media flow direction indicating whether
it is sending and/or receiving any media, or is inactive. When sending some media, the transceiver's
local track is used as the source of that media. Conversely, when receiving some media, that media is
delivered to the remote media track of the transceiver. As a convenience, the local track can be null
if the local peer does not have anything to send. In that case some empty media is automatically sent
instead (black frames for video, silence for audio) at very reduced rate. To completely stop sending,
the media direction must be changed instead.</p>
<p>Transceivers are owned by the peer connection which creates them, and cannot be destroyed nor removed
from the peer connection. They become invalid when the peer connection is closed, and should not be
used after that.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.TransceiverInitSettings.html">TransceiverInitSettings</a></h4>
      <section><p>Settings to create a new transceiver wrapper.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.VideoFrameQueue-1.html">VideoFrameQueue&lt;T&gt;</a></h4>
      <section><p>Small queue of video frames received from a source and pending delivery to a sink.
Used as temporary buffer between the WebRTC callback (push model) and the video
player rendering (pull model). This also handles dropping frames when the source
is faster than the sink, by limiting the maximum queue length.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.VideoProfile.html">VideoProfile</a></h4>
      <section><p>Video profile.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.VideoTrackSource.html">VideoTrackSource</a></h4>
      <section><p>Video source for WebRTC video tracks.</p>
<p>The video source is not bound to any peer connection, and can therefore be shared by multiple video
tracks from different peer connections. This is especially useful to share local video capture devices
(microphones) amongst multiple peer connections when building a multi-peer experience with a mesh topology
(one connection per pair of peers).</p>
<p>The user owns the video track source, and is in charge of keeping it alive until after all tracks using it
are destroyed, and then dispose of it. The behavior of disposing of the track source while a track is still
using it is undefined. The <a class="xref" href="Microsoft.MixedReality.WebRTC.VideoTrackSource.html#Microsoft_MixedReality_WebRTC_VideoTrackSource_Tracks">Tracks</a> property contains the list of tracks currently using the
source.</p>
</section>
    <h3 id="structs">Structs
  </h3>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.Argb32VideoFrame.html">Argb32VideoFrame</a></h4>
      <section><p>Single video frame encoded in ARGB interleaved format (32 bits per pixel).</p>
<p>The ARGB components are in the order of a little endian 32-bit integer, so
0xAARRGGBB, or (B, G, R, A) as a sequence of bytes in memory with B first
and A last.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.AudioFrame.html">AudioFrame</a></h4>
      <section><p>Single raw uncompressed audio frame.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.FrameRequest.html">FrameRequest</a></h4>
      <section><p>Request sent to an external video source via its registered callback to generate
a new video frame for the track(s) connected to it.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.I420AVideoFrame.html">I420AVideoFrame</a></h4>
      <section><p>Single video frame encoded in I420A format (triplanar YUV with optional alpha plane).
See e.g. <a href="https://wiki.videolan.org/YUV/#I420">https://wiki.videolan.org/YUV/#I420</a> for details.</p>
<p>The I420 format uses chroma downsampling in both directions, resulting in 12 bits per
pixel. With the optional alpha plane, the size increases to 20 bits per pixel.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.AudioReceiverStats.html">PeerConnection.AudioReceiverStats</a></h4>
      <section><p>Subset of RTCMediaStreamTrack (audio receiver) and RTCInboundRTPStreamStats.
See <a href="https://www.w3.org/TR/webrtc-stats/#aststats-dict*">https://www.w3.org/TR/webrtc-stats/#aststats-dict*</a>
and <a href="https://www.w3.org/TR/webrtc-stats/#inboundrtpstats-dict*">https://www.w3.org/TR/webrtc-stats/#inboundrtpstats-dict*</a>.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.AudioSenderStats.html">PeerConnection.AudioSenderStats</a></h4>
      <section><p>Subset of RTCMediaStreamTrack (audio sender) and RTCOutboundRTPStreamStats.
See <a href="https://www.w3.org/TR/webrtc-stats/#raststats-dict*">https://www.w3.org/TR/webrtc-stats/#raststats-dict*</a>
and <a href="https://www.w3.org/TR/webrtc-stats/#sentrtpstats-dict*">https://www.w3.org/TR/webrtc-stats/#sentrtpstats-dict*</a>.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.DataChannelStats.html">PeerConnection.DataChannelStats</a></h4>
      <section><p>Subset of RTCDataChannelStats. See <a href="https://www.w3.org/TR/webrtc-stats/#dcstats-dict*">https://www.w3.org/TR/webrtc-stats/#dcstats-dict*</a></p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.H264Config.html">PeerConnection.H264Config</a></h4>
      <section><p>Configuration for the Media Foundation H.264 encoder.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.TransportStats.html">PeerConnection.TransportStats</a></h4>
      <section><p>Subset of RTCTransportStats.
See <a href="https://www.w3.org/TR/webrtc-stats/#transportstats-dict*">https://www.w3.org/TR/webrtc-stats/#transportstats-dict*</a>.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.VideoReceiverStats.html">PeerConnection.VideoReceiverStats</a></h4>
      <section><p>Subset of RTCMediaStreamTrack (video receiver) + RTCInboundRTPStreamStats.
See <a href="https://www.w3.org/TR/webrtc-stats/#rvststats-dict*">https://www.w3.org/TR/webrtc-stats/#rvststats-dict*</a>
and <a href="https://www.w3.org/TR/webrtc-stats/#inboundrtpstats-dict*">https://www.w3.org/TR/webrtc-stats/#inboundrtpstats-dict*</a></p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.VideoSenderStats.html">PeerConnection.VideoSenderStats</a></h4>
      <section><p>Subset of RTCMediaStreamTrack (video sender) and RTCOutboundRTPStreamStats.
See <a href="https://www.w3.org/TR/webrtc-stats/#vsstats-dict*">https://www.w3.org/TR/webrtc-stats/#vsstats-dict*</a>
and <a href="https://www.w3.org/TR/webrtc-stats/#sentrtpstats-dict*">https://www.w3.org/TR/webrtc-stats/#sentrtpstats-dict*</a>.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.VideoCaptureDevice.html">VideoCaptureDevice</a></h4>
      <section><p>Identifier for a video capture device.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.VideoCaptureFormat.html">VideoCaptureFormat</a></h4>
      <section><p>Capture format for a video track.</p>
</section>
    <h3 id="interfaces">Interfaces
  </h3>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.IAudioSource.html">IAudioSource</a></h4>
      <section><p>Interface for audio sources, whether local sources/tracks or remote tracks.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.ILogSink.html">ILogSink</a></h4>
      <section><p>Interface for a sink receiving log messages. The sink can be registered with
<a class="xref" href="Microsoft.MixedReality.WebRTC.Logging.html#Microsoft_MixedReality_WebRTC_Logging_AddSink_Microsoft_MixedReality_WebRTC_ILogSink_Microsoft_MixedReality_WebRTC_LogSeverity_">AddSink(ILogSink, LogSeverity)</a> to receive logging messages.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.IVideoFrameQueue.html">IVideoFrameQueue</a></h4>
      <section><p>Interface for a queue of video frames.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.IVideoFrameStorage.html">IVideoFrameStorage</a></h4>
      <section><p>Interface for a storage of a single video frame.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.IVideoSource.html">IVideoSource</a></h4>
      <section><p>Interface for video sources, whether local or remote.</p>
</section>
    <h3 id="enums">Enums
  </h3>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.AudioDeviceModule.html">AudioDeviceModule</a></h4>
      <section><p>Audio device module for Windows Desktop platform.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.AudioTrackReadBuffer.PadBehavior.html">AudioTrackReadBuffer.PadBehavior</a></h4>
      <section><p>Controls the padding behavior of
<a class="xref" href="Microsoft.MixedReality.WebRTC.AudioTrackReadBuffer.html#Microsoft_MixedReality_WebRTC_AudioTrackReadBuffer_Read_System_Int32_System_Int32_System_Single___System_Int32__System_Boolean__Microsoft_MixedReality_WebRTC_AudioTrackReadBuffer_PadBehavior_">Read(Int32, Int32, Single[], out Int32, out Boolean, AudioTrackReadBuffer.PadBehavior)</a>
on underrun.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.BundlePolicy.html">BundlePolicy</a></h4>
      <section><p>Bundle policy.
See <a href="https://www.w3.org/TR/webrtc/#rtcbundlepolicy-enum">https://www.w3.org/TR/webrtc/#rtcbundlepolicy-enum</a>.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.DataChannel.ChannelState.html">DataChannel.ChannelState</a></h4>
      <section><p>Connection state of a data channel.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.IceConnectionState.html">IceConnectionState</a></h4>
      <section><p>State of an ICE connection.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.IceGatheringState.html">IceGatheringState</a></h4>
      <section><p>State of an ICE gathering process.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.IceTransportType.html">IceTransportType</a></h4>
      <section><p>Type of ICE candidates offered to the remote peer.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.Library.ShutdownOptionsFlags.html">Library.ShutdownOptionsFlags</a></h4>
      <section><p>Options for library shutdown.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.LogSeverity.html">LogSeverity</a></h4>
      <section><p>Log message severity.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.MediaKind.html">MediaKind</a></h4>
      <section><p>Type of media track or media transceiver.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.FrameHeightRoundMode.html">PeerConnection.FrameHeightRoundMode</a></h4>
      <section><p>Frame height round mode.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.H264Profile.html">PeerConnection.H264Profile</a></h4>
      <section><p>H.264 Encoding profile.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.H264RcMode.html">PeerConnection.H264RcMode</a></h4>
      <section><p>Rate control mode for the Media Foundation H.264.
See <a href="https://docs.microsoft.com/en-us/windows/win32/medfound/h-264-video-encoder">https://docs.microsoft.com/en-us/windows/win32/medfound/h-264-video-encoder</a> for details.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.TrackKind.html">PeerConnection.TrackKind</a></h4>
      <section><p>Kind of WebRTC track.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.SdpMessageType.html">SdpMessageType</a></h4>
      <section><p>Type of SDP message.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.SdpSemantic.html">SdpSemantic</a></h4>
      <section><p>SDP semantic used for (re)negotiating a peer connection.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.Transceiver.Direction.html">Transceiver.Direction</a></h4>
      <section><p>Direction of the media flowing inside the transceiver.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.VideoEncoding.html">VideoEncoding</a></h4>
      <section><p>Enumeration of video encodings.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.VideoProfileKind.html">VideoProfileKind</a></h4>
      <section><p>Kind of video profile. This corresponds to the <see xref="Windows.Media.Capture.KnownVideoProfile"></see>
enum of the <see xref="Windows.Media.Capture.MediaCapture"></see> API.</p>
</section>
    <h3 id="delegates">Delegates
  </h3>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.Argb32VideoFrameDelegate.html">Argb32VideoFrameDelegate</a></h4>
      <section><p>Delegate used for events when an ARGB-encoded video frame has been produced
and is ready for consumption.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.Argb32VideoFrameRequestDelegate.html">Argb32VideoFrameRequestDelegate</a></h4>
      <section><p>Callback invoked when the WebRTC pipeline needs an external video source to generate
a new video frame for the track(s) it is connected to.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.AudioFrameDelegate.html">AudioFrameDelegate</a></h4>
      <section><p>Delegate used for events when an audio frame has been produced
and is ready for consumption.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.DataChannel.BufferingChangedDelegate.html">DataChannel.BufferingChangedDelegate</a></h4>
      <section><p>Delegate for the <a class="xref" href="Microsoft.MixedReality.WebRTC.DataChannel.html#Microsoft_MixedReality_WebRTC_DataChannel_BufferingChanged">BufferingChanged</a> event.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.I420AVideoFrameDelegate.html">I420AVideoFrameDelegate</a></h4>
      <section><p>Delegate used for events when an I420-encoded video frame has been produced
and is ready for consumption.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.I420AVideoFrameRequestDelegate.html">I420AVideoFrameRequestDelegate</a></h4>
      <section><p>Callback invoked when the WebRTC pipeline needs an external video source to generate
a new video frame for the track(s) it is connected to.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.AudioTrackAddedDelegate.html">PeerConnection.AudioTrackAddedDelegate</a></h4>
      <section><p>Delegate for <a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.html#Microsoft_MixedReality_WebRTC_PeerConnection_AudioTrackAdded">AudioTrackAdded</a> event.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.AudioTrackRemovedDelegate.html">PeerConnection.AudioTrackRemovedDelegate</a></h4>
      <section><p>Delegate for <a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.html#Microsoft_MixedReality_WebRTC_PeerConnection_AudioTrackRemoved">AudioTrackRemoved</a> event.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.DataChannelAddedDelegate.html">PeerConnection.DataChannelAddedDelegate</a></h4>
      <section><p>Delegate for <a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.html#Microsoft_MixedReality_WebRTC_PeerConnection_DataChannelAdded">DataChannelAdded</a> event.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.DataChannelRemovedDelegate.html">PeerConnection.DataChannelRemovedDelegate</a></h4>
      <section><p>Delegate for <a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.html#Microsoft_MixedReality_WebRTC_PeerConnection_DataChannelRemoved">DataChannelRemoved</a> event.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.IceCandidateReadytoSendDelegate.html">PeerConnection.IceCandidateReadytoSendDelegate</a></h4>
      <section><p>Delegate for the <a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.html#Microsoft_MixedReality_WebRTC_PeerConnection_IceCandidateReadytoSend">IceCandidateReadytoSend</a> event.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.IceGatheringStateChangedDelegate.html">PeerConnection.IceGatheringStateChangedDelegate</a></h4>
      <section><p>Delegate for the <a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.html#Microsoft_MixedReality_WebRTC_PeerConnection_IceGatheringStateChanged">IceGatheringStateChanged</a> event.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.IceStateChangedDelegate.html">PeerConnection.IceStateChangedDelegate</a></h4>
      <section><p>Delegate for the <a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.html#Microsoft_MixedReality_WebRTC_PeerConnection_IceStateChanged">IceStateChanged</a> event.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.LocalSdpReadyToSendDelegate.html">PeerConnection.LocalSdpReadyToSendDelegate</a></h4>
      <section><p>Delegate for <a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.html#Microsoft_MixedReality_WebRTC_PeerConnection_LocalSdpReadytoSend">LocalSdpReadytoSend</a> event.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.TransceiverAddedDelegate.html">PeerConnection.TransceiverAddedDelegate</a></h4>
      <section><p>Delegate for <a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.html#Microsoft_MixedReality_WebRTC_PeerConnection_TransceiverAdded">TransceiverAdded</a> event.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.VideoTrackAddedDelegate.html">PeerConnection.VideoTrackAddedDelegate</a></h4>
      <section><p>Delegate for <a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.html#Microsoft_MixedReality_WebRTC_PeerConnection_VideoTrackAdded">VideoTrackAdded</a> event.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.VideoTrackRemovedDelegate.html">PeerConnection.VideoTrackRemovedDelegate</a></h4>
      <section><p>Delegate for <a class="xref" href="Microsoft.MixedReality.WebRTC.PeerConnection.html#Microsoft_MixedReality_WebRTC_PeerConnection_VideoTrackRemoved">VideoTrackRemoved</a> event.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.TransceiverAssociatedDelegate.html">TransceiverAssociatedDelegate</a></h4>
      <section><p>Delegate for the <a class="xref" href="Microsoft.MixedReality.WebRTC.Transceiver.html#Microsoft_MixedReality_WebRTC_Transceiver_Associated">Associated</a> event.</p>
</section>
      <h4><a class="xref" href="Microsoft.MixedReality.WebRTC.TransceiverDirectionChangedDelegate.html">TransceiverDirectionChangedDelegate</a></h4>
      <section><p>Delegate for the <a class="xref" href="Microsoft.MixedReality.WebRTC.Transceiver.html#Microsoft_MixedReality_WebRTC_Transceiver_DirectionChanged">DirectionChanged</a> event.</p>
</section>
</article>
          </div>
          
          <div class="hidden-sm col-md-2" role="complementary">
            <div class="sideaffix">
              <div class="contribution">
                <ul class="nav">
                </ul>
              </div>
              <nav class="bs-docs-sidebar hidden-print hidden-xs hidden-sm affix" id="affix">
                <h5>In This Article</h5>
                <div></div>
              </nav>
            </div>
          </div>
        </div>
      </div>
      
      <footer>
        <div class="grad-bottom"></div>
        <div class="footer">
          <div class="container">
            <span class="pull-right">
              <a href="#top">Back to top</a>
            </span>
            
            <span>Generated by <strong>DocFX</strong></span>
          </div>
        </div>
      </footer>
    </div>
    
    <script type="text/javascript" src="../styles/docfx.vendor.js"></script>
    <script type="text/javascript" src="../styles/docfx.js"></script>
    <script type="text/javascript" src="../styles/branches.gen.js"></script>
    <script type="text/javascript" src="../styles/branch-selector.js"></script>
    <script type="text/javascript" src="../styles/main.js"></script>
  </body>
</html>
